# Проект посвящен анализу тональности текстов и их классификации как положительных или отрицательных.

## Описание проекта

### Модули проекта:
1. **Загрузка и чтение данных (data_loader.py)**:
   Модуль загружает данные из различных источников в зависимости от расширения файла или типа пути: 
   - Определяет расширение файла,
   - Если файл имеет расширение .csv - пытается загрузить CSV файл с кодировкой ISO-8859-1. Если возникает ошибка UnicodeDecodeError, загружает файл с кодировкой utf-8, игнорируя ошибки.
   - Если файл имеет расширение .json - открывает JSON файл и загружает его содержимое.
   - Если путь содержит api - выполняет GET запрос к указанному API и возвращает текст ответа.
   - Если формат файла не поддерживается- - выводит сообщение о неподдерживаемом формате файла и возвращает None.

2. **Анализ качества данных (data_analysis.py)**:
  Модуль выполняет несколько функций для анализа и обработки данных в DataFrame:
   - Заменяет существующие заголовки первой строки на новые названия столбцов.
   - Подсчитывает количество и процент пропущенных значений для каждого столбца и возвращает результаты в виде словаря.
   - Возвращает информацию о типах данных в каждом столбце.
   - Описывает датасет, включая количество строк и столбцов, количество уникальных значений, пропущенные значения и использование памяти.
   - Генерирует подробный отчет о датасете, включая типы данных, пропущенные значения и основные статистики.

3. **Анализ распределения данных (analyze_distribution.py)**:
  Модуль анализирует распределение числовых данных в DataFrame. Он выполняет следующие задачи:
  - Определяет числовые столбцы.
  - Строит гистограммы для каждого числового признака.
  - Вычисляет асимметрию (skewness) и эксцесс (kurtosis) для этих признаков.
  - Возвращает результаты в виде DataFrame для удобства анализа.

4. **Предобработка текста (data_preprocessing.py)**:
   Модуль выполняет предварительную обработку текстовых данных в DataFrame:
   - Оставляет только столбцы target и text.
   - Удаляет строки, где target не равен 0 или 4.
   - Удаляет строки с пропущенными значениями и дубликаты.
   - Приводит текст к нижнему регистру и удаляет знаки препинания.
   - Удаляет часто встречающиеся английские слова (стоп-слова).
   - Выполняет лемматизацию текста.
   - Преобразует текст в TF-IDF векторы и добавляет их в DataFrame в виде нового дополнительного столбца.

5. **Обучение и оценка моделей (model_training.py)**:
   Модуль выполняет обучение и оценку различных моделей машинного обучения на основе текстовых данных:
   - Разделяет данные на обучающую и тестовую выборки.
   - Настраивает и обучает модели с использованием GridSearchCV для подбора лучших гиперпараметров.
   - Оценивает модели, выводит отчеты о классификации и точности, а также строит матрицы ошибок.
   - Поддерживает несколько моделей, включая Gradient Boosting, Random Forest, Extra Trees, CatBoost, SVC и XGBoost.

### Описание данных

В проекте использовался датасет Sentiment140 для анализа тональности твитов.
Ссылка на датасет: https://www.kaggle.com/datasets/kazanova/sentiment140
Датасет содержит 1 600 000 твитов, извлеченных с помощью twitter api. 
Твиты были аннотированы (0 - отрицательные, 2 - нейтральные, 4 - положительные) и их можно использовать для определения настроений.
Датасет содержит следующие признаки:
- **target**: класс твита, тип данных int64.
- **id**: идентификатор твита, тип данных int64.
- **date**: дата твита, тип данных object.
- **flag**: запрос (lyx). Если запроса нет, то это значение NO_QUERY, тип данных object.
- **user**: пользователь, который "твитнул", тип данных object.
- **text**: текст твита, тип данных object.

С целью проверки корректности работы механизмов обработки данных алгоритмами машинного обучения (ускорения процессов), использовалась выборка (по 500 строк) с положительными и отрицательными твитами.

### Используемые алгоритмы

Модуль `model_training.py` поддерживает обучение моделей с использованием следующих алгоритмов:
- K Neighbors Classifier
- Gradient Boosting Classifier
- Random Forest Classifier
- Extra Trees Classifier
- CatBoost Classifier
- SVM Classifier

Модели обучаются с использованием подбора гиперпараметров, а также выполняется отбор признаков с использованием `SelectKBest`.

### Структура проекта
- `main.ipynb`
- `data_loader.py`
- `data_analysis.py`
- `analyze_distribution.py`
- `data_preprocessing.py`
- `model_training.py`

## Визуализация результатов

- **Гистограммы распределения признаков для числовых данных**:  
  Модуль `analyze_distribution.py` строит гистограммы для каждого числового признака и оценивает распределение данных.

- **Матрицы ошибок для каждой обученной модели**:  
  Модуль `model_training.py` выводит матрицы ошибок для каждой обученной модели для оценки качества классификации.

- **Сравнение точности различных моделей на графике**:  
  Модуль `model_training.py` также визуализирует точность всех обученных моделей для сравнения их производительности.

## Результаты

Наилучшие результаты показала модель `SVM Classifier` — **71%**.

### Требования

- Python 3.10
- Необходимые библиотеки можно установить с помощью `pip`:

```bash
pip install -r requirements.txt